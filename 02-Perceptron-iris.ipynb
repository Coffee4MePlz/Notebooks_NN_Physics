{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuação do jupyter anterior. \n",
    "\n",
    "        01-Perceptron-iris.ipynb\n",
    "        \n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Breve descrição:\n",
    "\n",
    "O problema que resolveremos com o perceptron envolve a classificação das espécies de íris com base em suas características morfológicas. Especificamente, usaremos o perceptron para distinguir entre duas das três espécies de íris no dataset. \n",
    "\n",
    "No jupyter anterior usamos a biblioteca numpy para criar do zero um perceptron. Agora iremos utizar alguns ferramenta mais sofistica que iram faciliar todo o processo. \n",
    "\n",
    "* 1 - Aprendendo a criar um classe no numpy \n",
    "\n",
    "*  * 1.1 - Como criar um classe perceptron.\n",
    "*  * 1.2 - treinando o perceptron.\n",
    "\n",
    "*  2 - Introdução a bilbioteca Pytorch.\n",
    "*  * 2.1 - Aprendendo a criar um perceptron.\n",
    "*  * 2.2 - Como treinar um perceptron.\n",
    "*  * 2.3 - Como Treinar utilizando a GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Aprendendo a criar um classe no numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Para quem não sabe oque é classe ou programação orientada a objeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introdução às Classes em Python\n",
    "\n",
    "Python é uma linguagem de programação orientada a objetos, o que significa que ela suporta o uso de classes para organizar código em componentes reutilizáveis. Uma classe é como um blueprint para criar objetos; um objeto é uma instância de uma classe. Com classes, podemos modelar dados e funcionalidades complexas de maneira intuitiva e acessível.\n",
    "\n",
    "```python\n",
    "*Definindo uma Classe*\n",
    "\n",
    "    Uma classe é definida usando a palavra-chave class, seguida pelo nome da classe e dois pontos. Dentro da classe, definimos funções que são chamadas de métodos. O método `__init__()` é especial: ele é o construtor da classe e é chamado automaticamente quando um novo objeto da classe é criado.\n",
    "\n",
    "\n",
    "class Carro:\n",
    "    def __init__(self, marca, modelo, ano):\n",
    "        self.marca = marca\n",
    "        self.modelo = modelo\n",
    "        self.ano = ano\n",
    "\n",
    "Neste exemplo, Carro é uma classe com um método __init__() que inicializa três atributos: marca, modelo e ano. A palavra self é uma referência à instância atual da classe e é usada para acessar variáveis que pertencem à classe. Para criar uma instância de uma classe, você chama a classe usando o nome da classe seguido por parênteses, passando os argumentos que o método __init__() aceita:\n",
    "\n",
    "*Criando a instância:*\n",
    "\n",
    "meu_carro = Carro('Ford', 'Mustang', 2020)\n",
    "\n",
    "Aqui, meu_carro é um objeto da classe Carro. Podemos adicionar outros métodos à classe para definir comportamentos adicionais:\n",
    "\n",
    "class Carro:\n",
    "    def __init__(self, marca, modelo, ano):\n",
    "        self.marca = marca\n",
    "        self.modelo = modelo\n",
    "        self.ano = ano\n",
    "\n",
    "    def descricao(self):\n",
    "        return f\"{self.ano} {self.marca} {self.modelo}\"\n",
    "\n",
    "    def idade(self, ano_atual):\n",
    "        return ano_atual - self.ano\n",
    "\n",
    "Agora, a classe Carro tem dois métodos adicionais: descricao() que retorna uma string descrevendo o carro, e idade(), que calcula a idade do carro.\n",
    "\n",
    "\n",
    "*Herança:* permite que uma classe herde atributos e métodos de outra classe. Isso é útil para criar subcategorias que compartilham funcionalidades comuns.\n",
    "\n",
    "class CarroEletrico(Carro):\n",
    "    def __init__(self, marca, modelo, ano, autonomia):\n",
    "        super().__init__(marca, modelo, ano)\n",
    "        self.autonomia = autonomia\n",
    "\n",
    "    def descricao_bateria(self):\n",
    "        return f\"Este carro tem uma autonomia de {self.autonomia} km após uma carga completa.\"\n",
    "\n",
    "\n",
    "A classe 'CarroEletrico' herda de 'Carro' e adiciona um novo atributo autonomia, além de um novo método para descrever a bateria. Note que nesse caso temos 'super().__init__( .... )' este comando nos permite utilizar os metodos definido na class Carro()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Como criar um classe perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import numpy as np  # Biblioteca para operações numéricas em arrays e matrizes\n",
    "import matplotlib.pyplot as plt  # Biblioteca para criação de gráficos e visualizações\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,Entrada):\n",
    "        self.input = Entrada\n",
    "\n",
    "        # Inicialização dos pesos e bias\n",
    "        self.weights = np.random.randn(Entrada.shape[1])\n",
    "        self.bias = np.random.randn(1)\n",
    "\n",
    "    def pegar_pesos_bias(self):\n",
    "        return self.weights,self.bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um classe chamada perceptron que criar os pesos e bias. Também definimos um metodo que devolve quais são os pesos e bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array( [[0,1,2,3]])\n",
    "x = np.ones((10,4))\n",
    "neuronio = Perceptron(x)\n",
    "neuronio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronio.pegar_pesos_bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No jupyter anterior, nos aprendendo que o perceptron tem varias outras funções.\n",
    "\n",
    "Iremos implementar as outras partes como metodos dentro da clalsse perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, Entrada):\n",
    "        \"\"\"\n",
    "        Inicializa o perceptron com entradas, pesos aleatórios e bias.\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(Entrada.shape[1])  # pesos inicializados aleatoriamente\n",
    "        self.bias = np.random.randn(1)  # bias inicializado aleatoriamente\n",
    "\n",
    "    def pegar_pesos_bias(self):\n",
    "        \"\"\"\n",
    "        Retorna os pesos e bias do perceptron.\n",
    "        \"\"\"\n",
    "        return self.weights, self.bias\n",
    "    \n",
    "    def sigmoid(self, z_):\n",
    "        \"\"\"\n",
    "        Função de Ativação Sigmóide.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z_))\n",
    "    \n",
    "    def forward(self,x_):\n",
    "        \"\"\"\n",
    "        Realiza a propagação direta (forward pass) através de um perceptron simples.\n",
    "        \"\"\"\n",
    "        # Aplicação da função sigmoid para obter a probabilidade. \n",
    "        return self.sigmoid(np.dot(x_, self.weights) + self.bias ) \n",
    "        \n",
    "    def derivada_sigmoid(self, s_):\n",
    "        \"\"\"\n",
    "        Derivada da Função Sigmóide.\n",
    "        \"\"\"\n",
    "        return s_ * (1 - s_)\n",
    "    \n",
    "\n",
    "    def derivada_erro_quadratico_medio(self,y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Derivada do Erro Quadrático Médio.\n",
    "\n",
    "        \"\"\"\n",
    "        return 2 * (y_pred - y_true) / y_true.size\n",
    "    \n",
    "    def backpropagation(self,x_,y_ ,y_pred, learning_rate):\n",
    "        \"\"\"\n",
    "        Algoritmo de Backpropagation.\n",
    "\n",
    "        \"\"\"\n",
    "        # Derivada do erro\n",
    "        d_error = self.derivada_erro_quadratico_medio(y_pred, y_)\n",
    "        \n",
    "        # Derivadas da função de ativação\n",
    "        d_sigmoid = self.derivada_sigmoid(y_pred)\n",
    "        \n",
    "        # Gradientes\n",
    "        d_weights = np.dot(x_.T, d_error * d_sigmoid)\n",
    "        #d_weights = np.dot(x_, (d_error * d_sigmoid))  # Remove a transposta se x_ já estiver no formato correto\n",
    "        d_bias = np.sum(d_error * d_sigmoid)\n",
    "  \n",
    "        # Atualização dos pesos e bias\n",
    "        self.weights -= learning_rate * d_weights\n",
    "        self.bias -= learning_rate * d_bias\n",
    "\n",
    "def erro_quadratico_medio(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calcula o Erro Quadrático Médio (Mean Squared Error, MSE).\n",
    "    \"\"\"\n",
    "    return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def plot_decision_boundary(X, y, model_weights, model_bias, indice_f1=0, indice_f2=1):\n",
    "    \"\"\"\n",
    "    Plota o limite de decisão para um modelo de classificação binária junto com os dados de entrada.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Definir os limites do gráfico\n",
    "    x_min, x_max = X[:, indice_f1].min() - 0.5, X[:, indice_f1].max() + 0.5\n",
    "    y_min, y_max = X[:, indice_f2].min() - 0.5, X[:, indice_f2].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Predizer para cada ponto no meshgrid\n",
    "    Z = neuronio.sigmoid(np.dot(np.c_[xx.ravel(), yy.ravel()], model_weights) + model_bias)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Contorno e preenchimento\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, levels=np.linspace(0, 1, 3), cmap=plt.cm.coolwarm)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plotar os pontos de dados\n",
    "    plt.scatter(X[:, indice_f1], X[:, indice_f2], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel(f'{iris.feature_names[indice_f1]}')\n",
    "    plt.ylabel(f'{iris.feature_names[indice_f2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset Iris\n",
    "iris = datasets.load_iris() \n",
    "X = iris.data \n",
    "y = iris.target \n",
    "\n",
    "# Traduzir os nomes das colunas\n",
    "iris.feature_names = ['comprimento da sépala',\n",
    "                      'largura da sépala',\n",
    "                      'comprimento da pétala',\n",
    "                      'largura da pétala']\n",
    "\n",
    "# Filtrar para obter apenas as classes 0 e 2\n",
    "indices = np.where((y == 0) | (y == 2))  # Localiza índices das classes 0 e 2\n",
    "X = X[indices] \n",
    "y = y[indices] \n",
    "\n",
    "y = np.where(y == 2, 1, 0)  # Re-codificar classe 2 como 1, classe 0 permanece 0\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Normalização dos dados para melhor desempenho do modelo\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "\n",
    "# Instanciando a classe Perceptron\n",
    "neuronio = Perceptron(Entrada=X_train)\n",
    "neuronio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronio.pegar_pesos_bias() # Pesos criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neuronio.forward(X_train) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronio.backpropagation(X_train, y_train, y_pred, learning_rate=0.01)\n",
    "neuronio.pegar_pesos_bias()# Novos pesos e bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combina treino e teste para plotagem\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "\n",
    "# Dados do modelo (hipotético)\n",
    "weights = neuronio.pegar_pesos_bias()# Novos pesos e bias.\n",
    "\n",
    "model_weights = np.array([ weights[0][0],  weights[0][1]])  \n",
    "model_bias = weights[-1]                  \n",
    "# Plotar a fronteira de decisão e os pontos\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=0,indice_f2=1)\n",
    "plt.show()\n",
    "\n",
    "model_weights = np.array([ weights[0][2],  weights[0][3]])  # Substitua por seus pesos reais\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=2,indice_f2=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - treinando o perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Loss_acuracia = []\n",
    "Loss_mse = []\n",
    "\n",
    "# Treinamento do modelo\n",
    "for _ in range(1000):\n",
    "    y_pred = neuronio.forward(X_train)\n",
    "    neuronio.backpropagation(X_train, y_train, y_pred, learning_rate=0.1)\n",
    "    mse  = erro_quadratico_medio(y_train, y_pred)\n",
    "    \n",
    "    y_pred_test = [1 if neuronio.forward(i) > 0.5 else 0 for i in X_test]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    Loss_acuracia.append(accuracy)\n",
    "    Loss_mse.append(mse)\n",
    "\n",
    "# Avaliação\n",
    "plt.plot(Loss_acuracia);plt.show()\n",
    "plt.plot(Loss_mse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = neuronio.pegar_pesos_bias()# Novos pesos e bias.\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combina treino e teste para plotagem\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "\n",
    "# Dados do modelo (hipotético)\n",
    "weights = neuronio.pegar_pesos_bias()# Novos pesos e bias.\n",
    "\n",
    "model_weights = np.array([ weights[0][0],  weights[0][1]])  \n",
    "model_bias = weights[-1]                  \n",
    "# Plotar a fronteira de decisão e os pontos\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=0,indice_f2=1)\n",
    "plt.show()\n",
    "\n",
    "model_weights = np.array([ weights[0][2],  weights[0][3]])  # Substitua por seus pesos reais\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=2,indice_f2=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Introdução a bilbioteca Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao PyTorch 🚀\n",
    "\n",
    "![PyTorch Logo](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png)\n",
    "\n",
    "## O que é PyTorch?\n",
    "\n",
    "PyTorch é uma biblioteca de aprendizado de máquina de código aberto desenvolvida pelo Facebook's AI Research lab (FAIR). Desde o seu lançamento, tornou-se uma das ferramentas mais populares entre os pesquisadores e engenheiros de aprendizado de máquina devido à sua flexibilidade e eficiência. PyTorch é especialmente conhecido por sua facilidade de uso e a capacidade de facilitar a prototipagem rápida.\n",
    "\n",
    "## Para que serve PyTorch?\n",
    "\n",
    "PyTorch serve a vários propósitos no campo do aprendizado de máquina e deep learning:\n",
    "\n",
    "### 1. **Flexibilidade no Design de Modelos:** 💡\n",
    "   - **Autograd:** PyTorch oferece um sistema dinâmico de gradiente automático (Autograd) que permite modificações flexíveis e intuitivas em grafos de computação durante a execução. Isso é particularmente útil para designs experimentais onde ajustes frequentes nos modelos são necessários.\n",
    "\n",
    "### 2. **Facilita a Experimentação:** 🧪\n",
    "   - **Simplicidade e Intuitividade:** A interface simples de usar permite que desenvolvedores e pesquisadores construam protótipos de modelos de deep learning rapidamente, o que acelera o processo de experimentação e desenvolvimento.\n",
    "\n",
    "### 3. **Desempenho em Treinamento de Modelos:** ⚙️\n",
    "   - **GPU Acceleration:** PyTorch oferece suporte extenso para aceleração via GPUs, o que torna possível o treinamento de modelos complexos de forma mais rápida. A integração com CUDA garante que o processo seja eficiente e escalável.\n",
    "\n",
    "### 4. **Aplicações Práticas:** 🏭\n",
    "   - **De Pesquisas Acadêmicas a Produção:** PyTorch não só facilita a pesquisa e o desenvolvimento acadêmico, mas também é eficaz na implementação de soluções em produção. Isso é possível graças ao TorchScript, que é uma forma de converter modelos PyTorch em formatos que podem ser otimizados para ambientes de produção.\n",
    "\n",
    "Para mais informações, visite o [site oficial do PyTorch](https://pytorch.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Aprendendo a criar um perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1º - Importar as bibliotecas necessárias: Vamos precisar de torch para as operações tensoriais e torch.nn para as camadas e modelos de redes neurais.\n",
    "\n",
    "* 2º - Definir a classe do Perceptron: Criaremos uma classe que herda de torch.nn.Module. Nesta classe, definiremos a camada linear (pesos e bias). Forward Pass: Definiremos o método forward que realiza a passagem direta (cálculo da saída) do perceptron.\n",
    "\n",
    "* 3º - Inicializar o Perceptron: No construtor da classe, inicializaremos a camada linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1º Passo\n",
    "import torch as tc\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ºpasso\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__()\n",
    "        saida =1\n",
    "        \n",
    "        # Define a camada linear com input_dim entradas e 1 saída.\n",
    "        self.calculo_linear = nn.Linear(input_dim, saida)\n",
    "        \n",
    "        # Definir a função não linear.\n",
    "        self.funcao_de_ativacao = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.funcao_de_ativacao(self.calculo_linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma parte importante dentro do perceptron é dada pela funçao \"nn.Linear(input_dim, 1)\".\n",
    "\n",
    "Ela é responsavel pela parte matematica eq.(2) descrita no artigo. Para o codigo é importante saber que input_dim= é o números de entradas(em nosso problema 4) e a saida, como o propio nome indica,  é o número de saidas do perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3º passo\n",
    "perceptron = Perceptron(input_dim=X_train.shape[-1])\n",
    "# A dimensão do inpute deve ser igual ao numero de colunas do seu dataset\n",
    "# ou igual ao número de caracteristica.\n",
    "# Para o banco de dados de iris, o primeiro termo do X_train.shape\n",
    "# é o numero de dados, o segundo é o número de colunas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tentamos executar o metodo forward com os data set de iris , iremos ter probremas .\n",
    "Devido ao tipo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precismao que o todo os dados estejam no formato da biblioteca do pytorch(tensor), portanto iremos converter as variaveis de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.tensor(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tc.tensor(X_train, dtype=tc.float32)\n",
    "X_test  = tc.tensor(X_test, dtype=tc.float32)\n",
    "y_train = tc.tensor(y_train, dtype=tc.float32)\n",
    "y_test  = tc.tensor(y_test, dtype=tc.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que foi convertido para um tipo de variavel especifico dtype=tc.float32 que é o modo padrão que as variaveis são convertidas. \n",
    "\n",
    "Normalmente não precisamos especificar, mas nesse caso precismos pois a variavel estão sendo convertida para dtype=tc.float64, ocupando espaço na memoria desnecessario para nosos tipo de aplicação. Portanto é um boa pratic, neste caso, restrigir o tamanho da variavel e conseguintemente liberar espaço na memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados convertidos para tensores, podemos inserir dentro do perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saida = perceptron(X_train)\n",
    "saida[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente quando eu adicionar os dados de traino do arguimento do perceptron, ele já executa a metodo forward. Na celula acima estamos exibindo apenas as 5 primeira saida, referentes aos 5 primeiros valores de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saida.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro detalhe importante , é que a saida do perceptrontem formado [80, 1], logo o y_train deve ter o mesmo formato.\n",
    "Note que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reformat iremos usar :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Como treinar um perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos realizar o treinamento.\n",
    "\n",
    "Uma parte do procedimento é igual aos casos anteriores,mas temos que especifivar algus pontos cmo o otimizador e a função custo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a função de perda e o otimizador\n",
    "funcao_custo = nn.MSELoss()  # Erro quadrado medio\n",
    "optimizer = tc.optim.Adam(perceptron.parameters(), lr=0.1)  # Otimizador gradiente Descendente Estocatico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o perceptron\n",
    "num_epochs = 1000  # Número de épocas para treinar\n",
    "print_interval = num_epochs // 10  # Calcula o intervalo para imprimir 10 vezes\n",
    "for epoch in range(num_epochs):\n",
    "    # Zerar os gradientes do otimizador\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: Calcular a previsão do perceptron\n",
    "    outputs = perceptron(X_train)\n",
    "\n",
    "    # Calcular a perda\n",
    "    loss = funcao_custo(outputs, y_train)\n",
    "\n",
    "    # As duas etapas seguinte são passos do backpropagation\n",
    "    # Backward pass: Calcular os gradientes\n",
    "    loss.backward()\n",
    "\n",
    "    # Atualizar os pesos\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printar a perda\n",
    "    # Condição para imprimir a perda 10 vezes durante o treinamento\n",
    "    if (epoch % print_interval == 0) or (epoch == num_epochs - 1):\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualiza os resutlados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenção dos pesos e bias do modelo\n",
    "weights_tc = perceptron.calculo_linear.weight.data.numpy()[0]\n",
    "bias_tc = perceptron.calculo_linear.bias.data.numpy()\n",
    "weights_tc,bias_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, model_weights, model_bias, indice_f1=0, indice_f2=1):\n",
    "    \"\"\"\n",
    "    Plota o limite de decisão para um modelo de classificação binária junto com os dados de entrada.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Definir os limites do gráfico\n",
    "    x_min, x_max = X[:, indice_f1].min() - 0.5, X[:, indice_f1].max() + 0.5\n",
    "    y_min, y_max = X[:, indice_f2].min() - 0.5, X[:, indice_f2].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    val = np.dot(np.c_[xx.ravel(), yy.ravel()], model_weights) + model_bias\n",
    "    # Predizer para cada ponto no meshgrid\n",
    "    Z = tc.sigmoid(tc.tensor(val))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Contorno e preenchimento\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, levels=np.linspace(0, 1, 3), cmap=plt.cm.coolwarm)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plotar os pontos de dados\n",
    "    plt.scatter(X[:, indice_f1], X[:, indice_f2], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel(f'{iris.feature_names[indice_f1]}')\n",
    "    plt.ylabel(f'{iris.feature_names[indice_f2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = np.array([ weights_tc[0],  weights_tc[1]])  \n",
    "               \n",
    "# Plotar a fronteira de decisão e os pontos\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, bias_tc ,indice_f1=0,indice_f2=1)\n",
    "plt.show()\n",
    "\n",
    "model_weights = np.array([ weights_tc[2],  weights_tc[3]])  # Substitua por seus pesos reais\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, bias_tc ,indice_f1=2,indice_f2=3)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
