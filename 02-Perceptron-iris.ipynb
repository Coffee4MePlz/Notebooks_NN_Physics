{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continua√ß√£o do jupyter anterior. \n",
    "\n",
    "        01-Perceptron-iris.ipynb\n",
    "        \n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Breve descri√ß√£o:\n",
    "\n",
    "O problema que resolveremos com o perceptron envolve a classifica√ß√£o das esp√©cies de √≠ris com base em suas caracter√≠sticas morfol√≥gicas. Especificamente, usaremos o perceptron para distinguir entre duas das tr√™s esp√©cies de √≠ris no dataset. \n",
    "\n",
    "No jupyter anterior usamos a biblioteca numpy para criar do zero um perceptron. Agora iremos utizar alguns ferramenta mais sofistica que iram faciliar todo o processo. \n",
    "\n",
    "* 1 - Aprendendo a criar um classe no numpy \n",
    "\n",
    "*  * 1.1 - Como criar um classe perceptron.\n",
    "*  * 1.2 - treinando o perceptron.\n",
    "\n",
    "*  2 - Introdu√ß√£o a bilbioteca Pytorch.\n",
    "*  * 2.1 - Aprendendo a criar um perceptron.\n",
    "*  * 2.2 - Como treinar um perceptron.\n",
    "*  * 2.3 - Como Treinar utilizando a GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Aprendendo a criar um classe no numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Para quem n√£o sabe oque √© classe ou programa√ß√£o orientada a objeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introdu√ß√£o √†s Classes em Python\n",
    "\n",
    "Python √© uma linguagem de programa√ß√£o orientada a objetos, o que significa que ela suporta o uso de classes para organizar c√≥digo em componentes reutiliz√°veis. Uma classe √© como um blueprint para criar objetos; um objeto √© uma inst√¢ncia de uma classe. Com classes, podemos modelar dados e funcionalidades complexas de maneira intuitiva e acess√≠vel.\n",
    "\n",
    "```python\n",
    "*Definindo uma Classe*\n",
    "\n",
    "    Uma classe √© definida usando a palavra-chave class, seguida pelo nome da classe e dois pontos. Dentro da classe, definimos fun√ß√µes que s√£o chamadas de m√©todos. O m√©todo `__init__()` √© especial: ele √© o construtor da classe e √© chamado automaticamente quando um novo objeto da classe √© criado.\n",
    "\n",
    "\n",
    "class Carro:\n",
    "    def __init__(self, marca, modelo, ano):\n",
    "        self.marca = marca\n",
    "        self.modelo = modelo\n",
    "        self.ano = ano\n",
    "\n",
    "Neste exemplo, Carro √© uma classe com um m√©todo __init__() que inicializa tr√™s atributos: marca, modelo e ano. A palavra self √© uma refer√™ncia √† inst√¢ncia atual da classe e √© usada para acessar vari√°veis que pertencem √† classe. Para criar uma inst√¢ncia de uma classe, voc√™ chama a classe usando o nome da classe seguido por par√™nteses, passando os argumentos que o m√©todo __init__() aceita:\n",
    "\n",
    "*Criando a inst√¢ncia:*\n",
    "\n",
    "meu_carro = Carro('Ford', 'Mustang', 2020)\n",
    "\n",
    "Aqui, meu_carro √© um objeto da classe Carro. Podemos adicionar outros m√©todos √† classe para definir comportamentos adicionais:\n",
    "\n",
    "class Carro:\n",
    "    def __init__(self, marca, modelo, ano):\n",
    "        self.marca = marca\n",
    "        self.modelo = modelo\n",
    "        self.ano = ano\n",
    "\n",
    "    def descricao(self):\n",
    "        return f\"{self.ano} {self.marca} {self.modelo}\"\n",
    "\n",
    "    def idade(self, ano_atual):\n",
    "        return ano_atual - self.ano\n",
    "\n",
    "Agora, a classe Carro tem dois m√©todos adicionais: descricao() que retorna uma string descrevendo o carro, e idade(), que calcula a idade do carro.\n",
    "\n",
    "\n",
    "*Heran√ßa:* permite que uma classe herde atributos e m√©todos de outra classe. Isso √© √∫til para criar subcategorias que compartilham funcionalidades comuns.\n",
    "\n",
    "class CarroEletrico(Carro):\n",
    "    def __init__(self, marca, modelo, ano, autonomia):\n",
    "        super().__init__(marca, modelo, ano)\n",
    "        self.autonomia = autonomia\n",
    "\n",
    "    def descricao_bateria(self):\n",
    "        return f\"Este carro tem uma autonomia de {self.autonomia} km ap√≥s uma carga completa.\"\n",
    "\n",
    "\n",
    "A classe 'CarroEletrico' herda de 'Carro' e adiciona um novo atributo autonomia, al√©m de um novo m√©todo para descrever a bateria. Note que nesse caso temos 'super().__init__( .... )' este comando nos permite utilizar os metodos definido na class Carro()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Como criar um classe perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas necess√°rias\n",
    "import numpy as np  # Biblioteca para opera√ß√µes num√©ricas em arrays e matrizes\n",
    "import matplotlib.pyplot as plt  # Biblioteca para cria√ß√£o de gr√°ficos e visualiza√ß√µes\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,Entrada):\n",
    "        self.input = Entrada\n",
    "\n",
    "        # Inicializa√ß√£o dos pesos e bias\n",
    "        self.weights = np.random.randn(Entrada.shape[1])\n",
    "        self.bias = np.random.randn(1)\n",
    "\n",
    "    def pegar_pesos_bias(self):\n",
    "        return self.weights,self.bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um classe chamada perceptron que criar os pesos e bias. Tamb√©m definimos um metodo que devolve quais s√£o os pesos e bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array( [[0,1,2,3]])\n",
    "x = np.ones((10,4))\n",
    "neuronio = Perceptron(x)\n",
    "neuronio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronio.pegar_pesos_bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No jupyter anterior, nos aprendendo que o perceptron tem varias outras fun√ß√µes.\n",
    "\n",
    "Iremos implementar as outras partes como metodos dentro da clalsse perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, Entrada):\n",
    "        \"\"\"\n",
    "        Inicializa o perceptron com entradas, pesos aleat√≥rios e bias.\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(Entrada.shape[1])  # pesos inicializados aleatoriamente\n",
    "        self.bias = np.random.randn(1)  # bias inicializado aleatoriamente\n",
    "\n",
    "    def pegar_pesos_bias(self):\n",
    "        \"\"\"\n",
    "        Retorna os pesos e bias do perceptron.\n",
    "        \"\"\"\n",
    "        return self.weights, self.bias\n",
    "    \n",
    "    def sigmoid(self, z_):\n",
    "        \"\"\"\n",
    "        Fun√ß√£o de Ativa√ß√£o Sigm√≥ide.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z_))\n",
    "    \n",
    "    def forward(self,x_):\n",
    "        \"\"\"\n",
    "        Realiza a propaga√ß√£o direta (forward pass) atrav√©s de um perceptron simples.\n",
    "        \"\"\"\n",
    "        # Aplica√ß√£o da fun√ß√£o sigmoid para obter a probabilidade. \n",
    "        return self.sigmoid(np.dot(x_, self.weights) + self.bias ) \n",
    "        \n",
    "    def derivada_sigmoid(self, s_):\n",
    "        \"\"\"\n",
    "        Derivada da Fun√ß√£o Sigm√≥ide.\n",
    "        \"\"\"\n",
    "        return s_ * (1 - s_)\n",
    "    \n",
    "\n",
    "    def derivada_erro_quadratico_medio(self,y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Derivada do Erro Quadr√°tico M√©dio.\n",
    "\n",
    "        \"\"\"\n",
    "        return 2 * (y_pred - y_true) / y_true.size\n",
    "    \n",
    "    def backpropagation(self,x_,y_ ,y_pred, learning_rate):\n",
    "        \"\"\"\n",
    "        Algoritmo de Backpropagation.\n",
    "\n",
    "        \"\"\"\n",
    "        # Derivada do erro\n",
    "        d_error = self.derivada_erro_quadratico_medio(y_pred, y_)\n",
    "        \n",
    "        # Derivadas da fun√ß√£o de ativa√ß√£o\n",
    "        d_sigmoid = self.derivada_sigmoid(y_pred)\n",
    "        \n",
    "        # Gradientes\n",
    "        d_weights = np.dot(x_.T, d_error * d_sigmoid)\n",
    "        #d_weights = np.dot(x_, (d_error * d_sigmoid))  # Remove a transposta se x_ j√° estiver no formato correto\n",
    "        d_bias = np.sum(d_error * d_sigmoid)\n",
    "  \n",
    "        # Atualiza√ß√£o dos pesos e bias\n",
    "        self.weights -= learning_rate * d_weights\n",
    "        self.bias -= learning_rate * d_bias\n",
    "\n",
    "def erro_quadratico_medio(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calcula o Erro Quadr√°tico M√©dio (Mean Squared Error, MSE).\n",
    "    \"\"\"\n",
    "    return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def plot_decision_boundary(X, y, model_weights, model_bias, indice_f1=0, indice_f2=1):\n",
    "    \"\"\"\n",
    "    Plota o limite de decis√£o para um modelo de classifica√ß√£o bin√°ria junto com os dados de entrada.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Definir os limites do gr√°fico\n",
    "    x_min, x_max = X[:, indice_f1].min() - 0.5, X[:, indice_f1].max() + 0.5\n",
    "    y_min, y_max = X[:, indice_f2].min() - 0.5, X[:, indice_f2].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Predizer para cada ponto no meshgrid\n",
    "    Z = neuronio.sigmoid(np.dot(np.c_[xx.ravel(), yy.ravel()], model_weights) + model_bias)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Contorno e preenchimento\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, levels=np.linspace(0, 1, 3), cmap=plt.cm.coolwarm)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plotar os pontos de dados\n",
    "    plt.scatter(X[:, indice_f1], X[:, indice_f2], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel(f'{iris.feature_names[indice_f1]}')\n",
    "    plt.ylabel(f'{iris.feature_names[indice_f2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset Iris\n",
    "iris = datasets.load_iris() \n",
    "X = iris.data \n",
    "y = iris.target \n",
    "\n",
    "# Traduzir os nomes das colunas\n",
    "iris.feature_names = ['comprimento da s√©pala',\n",
    "                      'largura da s√©pala',\n",
    "                      'comprimento da p√©tala',\n",
    "                      'largura da p√©tala']\n",
    "\n",
    "# Filtrar para obter apenas as classes 0 e 2\n",
    "indices = np.where((y == 0) | (y == 2))  # Localiza √≠ndices das classes 0 e 2\n",
    "X = X[indices] \n",
    "y = y[indices] \n",
    "\n",
    "y = np.where(y == 2, 1, 0)  # Re-codificar classe 2 como 1, classe 0 permanece 0\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Normaliza√ß√£o dos dados para melhor desempenho do modelo\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "\n",
    "# Instanciando a classe Perceptron\n",
    "neuronio = Perceptron(Entrada=X_train)\n",
    "neuronio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronio.pegar_pesos_bias() # Pesos criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neuronio.forward(X_train) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronio.backpropagation(X_train, y_train, y_pred, learning_rate=0.01)\n",
    "neuronio.pegar_pesos_bias()# Novos pesos e bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combina treino e teste para plotagem\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "\n",
    "# Dados do modelo (hipot√©tico)\n",
    "weights = neuronio.pegar_pesos_bias()# Novos pesos e bias.\n",
    "\n",
    "model_weights = np.array([ weights[0][0],  weights[0][1]])  \n",
    "model_bias = weights[-1]                  \n",
    "# Plotar a fronteira de decis√£o e os pontos\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=0,indice_f2=1)\n",
    "plt.show()\n",
    "\n",
    "model_weights = np.array([ weights[0][2],  weights[0][3]])  # Substitua por seus pesos reais\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=2,indice_f2=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - treinando o perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Loss_acuracia = []\n",
    "Loss_mse = []\n",
    "\n",
    "# Treinamento do modelo\n",
    "for _ in range(1000):\n",
    "    y_pred = neuronio.forward(X_train)\n",
    "    neuronio.backpropagation(X_train, y_train, y_pred, learning_rate=0.1)\n",
    "    mse  = erro_quadratico_medio(y_train, y_pred)\n",
    "    \n",
    "    y_pred_test = [1 if neuronio.forward(i) > 0.5 else 0 for i in X_test]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    Loss_acuracia.append(accuracy)\n",
    "    Loss_mse.append(mse)\n",
    "\n",
    "# Avalia√ß√£o\n",
    "plt.plot(Loss_acuracia);plt.show()\n",
    "plt.plot(Loss_mse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = neuronio.pegar_pesos_bias()# Novos pesos e bias.\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combina treino e teste para plotagem\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "\n",
    "# Dados do modelo (hipot√©tico)\n",
    "weights = neuronio.pegar_pesos_bias()# Novos pesos e bias.\n",
    "\n",
    "model_weights = np.array([ weights[0][0],  weights[0][1]])  \n",
    "model_bias = weights[-1]                  \n",
    "# Plotar a fronteira de decis√£o e os pontos\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=0,indice_f2=1)\n",
    "plt.show()\n",
    "\n",
    "model_weights = np.array([ weights[0][2],  weights[0][3]])  # Substitua por seus pesos reais\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, model_bias,indice_f1=2,indice_f2=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Introdu√ß√£o a bilbioteca Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdu√ß√£o ao PyTorch üöÄ\n",
    "\n",
    "![PyTorch Logo](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png)\n",
    "\n",
    "## O que √© PyTorch?\n",
    "\n",
    "PyTorch √© uma biblioteca de aprendizado de m√°quina de c√≥digo aberto desenvolvida pelo Facebook's AI Research lab (FAIR). Desde o seu lan√ßamento, tornou-se uma das ferramentas mais populares entre os pesquisadores e engenheiros de aprendizado de m√°quina devido √† sua flexibilidade e efici√™ncia. PyTorch √© especialmente conhecido por sua facilidade de uso e a capacidade de facilitar a prototipagem r√°pida.\n",
    "\n",
    "## Para que serve PyTorch?\n",
    "\n",
    "PyTorch serve a v√°rios prop√≥sitos no campo do aprendizado de m√°quina e deep learning:\n",
    "\n",
    "### 1. **Flexibilidade no Design de Modelos:** üí°\n",
    "   - **Autograd:** PyTorch oferece um sistema din√¢mico de gradiente autom√°tico (Autograd) que permite modifica√ß√µes flex√≠veis e intuitivas em grafos de computa√ß√£o durante a execu√ß√£o. Isso √© particularmente √∫til para designs experimentais onde ajustes frequentes nos modelos s√£o necess√°rios.\n",
    "\n",
    "### 2. **Facilita a Experimenta√ß√£o:** üß™\n",
    "   - **Simplicidade e Intuitividade:** A interface simples de usar permite que desenvolvedores e pesquisadores construam prot√≥tipos de modelos de deep learning rapidamente, o que acelera o processo de experimenta√ß√£o e desenvolvimento.\n",
    "\n",
    "### 3. **Desempenho em Treinamento de Modelos:** ‚öôÔ∏è\n",
    "   - **GPU Acceleration:** PyTorch oferece suporte extenso para acelera√ß√£o via GPUs, o que torna poss√≠vel o treinamento de modelos complexos de forma mais r√°pida. A integra√ß√£o com CUDA garante que o processo seja eficiente e escal√°vel.\n",
    "\n",
    "### 4. **Aplica√ß√µes Pr√°ticas:** üè≠\n",
    "   - **De Pesquisas Acad√™micas a Produ√ß√£o:** PyTorch n√£o s√≥ facilita a pesquisa e o desenvolvimento acad√™mico, mas tamb√©m √© eficaz na implementa√ß√£o de solu√ß√µes em produ√ß√£o. Isso √© poss√≠vel gra√ßas ao TorchScript, que √© uma forma de converter modelos PyTorch em formatos que podem ser otimizados para ambientes de produ√ß√£o.\n",
    "\n",
    "Para mais informa√ß√µes, visite o [site oficial do PyTorch](https://pytorch.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Aprendendo a criar um perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1¬∫ - Importar as bibliotecas necess√°rias: Vamos precisar de torch para as opera√ß√µes tensoriais e torch.nn para as camadas e modelos de redes neurais.\n",
    "\n",
    "* 2¬∫ - Definir a classe do Perceptron: Criaremos uma classe que herda de torch.nn.Module. Nesta classe, definiremos a camada linear (pesos e bias). Forward Pass: Definiremos o m√©todo forward que realiza a passagem direta (c√°lculo da sa√≠da) do perceptron.\n",
    "\n",
    "* 3¬∫ - Inicializar o Perceptron: No construtor da classe, inicializaremos a camada linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1¬∫ Passo\n",
    "import torch as tc\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2¬∫passo\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__()\n",
    "        saida =1\n",
    "        \n",
    "        # Define a camada linear com input_dim entradas e 1 sa√≠da.\n",
    "        self.calculo_linear = nn.Linear(input_dim, saida)\n",
    "        \n",
    "        # Definir a fun√ß√£o n√£o linear.\n",
    "        self.funcao_de_ativacao = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.funcao_de_ativacao(self.calculo_linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma parte importante dentro do perceptron √© dada pela fun√ßao \"nn.Linear(input_dim, 1)\".\n",
    "\n",
    "Ela √© responsavel pela parte matematica eq.(2) descrita no artigo. Para o codigo √© importante saber que input_dim= √© o n√∫meros de entradas(em nosso problema 4) e a saida, como o propio nome indica,  √© o n√∫mero de saidas do perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3¬∫ passo\n",
    "perceptron = Perceptron(input_dim=X_train.shape[-1])\n",
    "# A dimens√£o do inpute deve ser igual ao numero de colunas do seu dataset\n",
    "# ou igual ao n√∫mero de caracteristica.\n",
    "# Para o banco de dados de iris, o primeiro termo do X_train.shape\n",
    "# √© o numero de dados, o segundo √© o n√∫mero de colunas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tentamos executar o metodo forward com os data set de iris , iremos ter probremas .\n",
    "Devido ao tipo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precismao que o todo os dados estejam no formato da biblioteca do pytorch(tensor), portanto iremos converter as variaveis de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.tensor(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tc.tensor(X_train, dtype=tc.float32)\n",
    "X_test  = tc.tensor(X_test, dtype=tc.float32)\n",
    "y_train = tc.tensor(y_train, dtype=tc.float32)\n",
    "y_test  = tc.tensor(y_test, dtype=tc.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que foi convertido para um tipo de variavel especifico dtype=tc.float32 que √© o modo padr√£o que as variaveis s√£o convertidas. \n",
    "\n",
    "Normalmente n√£o precisamos especificar, mas nesse caso precismos pois a variavel est√£o sendo convertida para dtype=tc.float64, ocupando espa√ßo na memoria desnecessario para nosos tipo de aplica√ß√£o. Portanto √© um boa pratic, neste caso, restrigir o tamanho da variavel e conseguintemente liberar espa√ßo na memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados convertidos para tensores, podemos inserir dentro do perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saida = perceptron(X_train)\n",
    "saida[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente quando eu adicionar os dados de traino do arguimento do perceptron, ele j√° executa a metodo forward. Na celula acima estamos exibindo apenas as 5 primeira saida, referentes aos 5 primeiros valores de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saida.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro detalhe importante , √© que a saida do perceptrontem formado [80, 1], logo o y_train deve ter o mesmo formato.\n",
    "Note que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reformat iremos usar :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Como treinar um perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos realizar o treinamento.\n",
    "\n",
    "Uma parte do procedimento √© igual aos casos anteriores,mas temos que especifivar algus pontos cmo o otimizador e a fun√ß√£o custo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a fun√ß√£o de perda e o otimizador\n",
    "funcao_custo = nn.MSELoss()  # Erro quadrado medio\n",
    "optimizer = tc.optim.Adam(perceptron.parameters(), lr=0.1)  # Otimizador gradiente Descendente Estocatico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o perceptron\n",
    "num_epochs = 1000  # N√∫mero de √©pocas para treinar\n",
    "print_interval = num_epochs // 10  # Calcula o intervalo para imprimir 10 vezes\n",
    "for epoch in range(num_epochs):\n",
    "    # Zerar os gradientes do otimizador\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: Calcular a previs√£o do perceptron\n",
    "    outputs = perceptron(X_train)\n",
    "\n",
    "    # Calcular a perda\n",
    "    loss = funcao_custo(outputs, y_train)\n",
    "\n",
    "    # As duas etapas seguinte s√£o passos do backpropagation\n",
    "    # Backward pass: Calcular os gradientes\n",
    "    loss.backward()\n",
    "\n",
    "    # Atualizar os pesos\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printar a perda\n",
    "    # Condi√ß√£o para imprimir a perda 10 vezes durante o treinamento\n",
    "    if (epoch % print_interval == 0) or (epoch == num_epochs - 1):\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualiza os resutlados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obten√ß√£o dos pesos e bias do modelo\n",
    "weights_tc = perceptron.calculo_linear.weight.data.numpy()[0]\n",
    "bias_tc = perceptron.calculo_linear.bias.data.numpy()\n",
    "weights_tc,bias_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, model_weights, model_bias, indice_f1=0, indice_f2=1):\n",
    "    \"\"\"\n",
    "    Plota o limite de decis√£o para um modelo de classifica√ß√£o bin√°ria junto com os dados de entrada.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Definir os limites do gr√°fico\n",
    "    x_min, x_max = X[:, indice_f1].min() - 0.5, X[:, indice_f1].max() + 0.5\n",
    "    y_min, y_max = X[:, indice_f2].min() - 0.5, X[:, indice_f2].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    val = np.dot(np.c_[xx.ravel(), yy.ravel()], model_weights) + model_bias\n",
    "    # Predizer para cada ponto no meshgrid\n",
    "    Z = tc.sigmoid(tc.tensor(val))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Contorno e preenchimento\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, levels=np.linspace(0, 1, 3), cmap=plt.cm.coolwarm)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plotar os pontos de dados\n",
    "    plt.scatter(X[:, indice_f1], X[:, indice_f2], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel(f'{iris.feature_names[indice_f1]}')\n",
    "    plt.ylabel(f'{iris.feature_names[indice_f2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = np.array([ weights_tc[0],  weights_tc[1]])  \n",
    "               \n",
    "# Plotar a fronteira de decis√£o e os pontos\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, bias_tc ,indice_f1=0,indice_f2=1)\n",
    "plt.show()\n",
    "\n",
    "model_weights = np.array([ weights_tc[2],  weights_tc[3]])  # Substitua por seus pesos reais\n",
    "plot_decision_boundary(X_combined, y_combined, model_weights, bias_tc ,indice_f1=2,indice_f2=3)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
